<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Yu Sun</title>
    <link>http://localhost:1313/tags/nlp/</link>
    <description>Recent content in NLP on Yu Sun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 26 Jan 2021 15:01:46 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gradient Descent</title>
      <link>http://localhost:1313/post/gradient_descent/</link>
      <pubDate>Tue, 26 Jan 2021 15:01:46 +0800</pubDate>
      
      <guid>http://localhost:1313/post/gradient_descent/</guid>
      <description>在之前Regression的step 3中，需要解决下面问题：$\theta^*=arg\ min_\theta L(\theta)$，其中$L$是损失函数，$\t</description>
    </item>
    
    <item>
      <title>Where does the error come from</title>
      <link>http://localhost:1313/post/basic_concept/</link>
      <pubDate>Tue, 26 Jan 2021 10:14:46 +0800</pubDate>
      
      <guid>http://localhost:1313/post/basic_concept/</guid>
      <description>回顾 上节课已知，越复杂的模型不一定性能越小，会有average error。而本节课可以看到error可以来自两个方面，一个是bias，一个是</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>http://localhost:1313/post/introduction/</link>
      <pubDate>Mon, 25 Jan 2021 15:43:24 +0800</pubDate>
      
      <guid>http://localhost:1313/post/introduction/</guid>
      <description>本篇主要介绍机器学习主要概念。 Learning Map **机器学习就是自动找函数。**例如，语音识别要找到从声音讯号到文字的函数，图像识别要找从图片到文字的函数</description>
    </item>
    
    <item>
      <title>Regression: Case Study</title>
      <link>http://localhost:1313/post/regression/</link>
      <pubDate>Mon, 25 Jan 2021 14:49:49 +0800</pubDate>
      
      <guid>http://localhost:1313/post/regression/</guid>
      <description>预测宝可梦进化后的CP (Combat Power)值：期望根据已有的宝可梦进化前后的信息，来预测某只宝可梦进化后的CP值的大小。 设定参数 输入$x$：一只宝</description>
    </item>
    
  </channel>
</rss>
