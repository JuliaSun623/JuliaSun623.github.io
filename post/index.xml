<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Yu Sun</title>
    <link>http://localhost:1313/post/</link>
    <description>Recent content in Posts on Yu Sun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 31 Jan 2021 16:20:46 +0800</lastBuildDate><atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Backpropagation</title>
      <link>http://localhost:1313/post/backprop/</link>
      <pubDate>Sun, 31 Jan 2021 16:20:46 +0800</pubDate>
      
      <guid>http://localhost:1313/post/backprop/</guid>
      <description>Gradient Descent gradient descent的使用方法，跟前面讲到的linear Regression或Logistic Regression是一样的，唯一的区别就在于</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:1313/post/dl/</link>
      <pubDate>Sat, 30 Jan 2021 13:51:49 +0800</pubDate>
      
      <guid>http://localhost:1313/post/dl/</guid>
      <description>深度学习历史 1958：Perceptron(linear model)，提出感知机 和Logistic Regression类似，只是少了sigm</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>http://localhost:1313/post/logistic_regression/</link>
      <pubDate>Thu, 28 Jan 2021 10:42:06 +0800</pubDate>
      
      <guid>http://localhost:1313/post/logistic_regression/</guid>
      <description>Logistic Regression过程 1. 确定model（function set） 想要找到$P_{w,b}(C_1|x)$，如果$P_{w,b}(C_1|</description>
    </item>
    
    <item>
      <title>Classification: Probabilistic Generative Model</title>
      <link>http://localhost:1313/post/classification/</link>
      <pubDate>Wed, 27 Jan 2021 10:32:36 +0800</pubDate>
      
      <guid>http://localhost:1313/post/classification/</guid>
      <description>概念 任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。 依旧用宝可梦的例子：宝可</description>
    </item>
    
    <item>
      <title>New Optimizers for Deep Learning</title>
      <link>http://localhost:1313/post/optimization/</link>
      <pubDate>Wed, 27 Jan 2021 09:18:41 +0800</pubDate>
      
      <guid>http://localhost:1313/post/optimization/</guid>
      <description>本篇为助教选修课 优化算法概述 $\theta_t$：在第t步第模型参数 $\nabla L(\theta_t)$或$g_t$：在$\theta_t$处的梯度，</description>
    </item>
    
    <item>
      <title>Gradient Descent</title>
      <link>http://localhost:1313/post/gradient_descent/</link>
      <pubDate>Tue, 26 Jan 2021 15:01:46 +0800</pubDate>
      
      <guid>http://localhost:1313/post/gradient_descent/</guid>
      <description>在之前Regression的step 3中，需要解决下面问题：$\theta^*=arg\ min_\theta L(\theta)$，其中$L$是损失函数，$\t</description>
    </item>
    
    <item>
      <title>Where does the error come from</title>
      <link>http://localhost:1313/post/basic_concept/</link>
      <pubDate>Tue, 26 Jan 2021 10:14:46 +0800</pubDate>
      
      <guid>http://localhost:1313/post/basic_concept/</guid>
      <description>回顾 上节课已知，越复杂的模型不一定性能越小，会有average error。而本节课可以看到error可以来自两个方面，一个是bias，一个是</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>http://localhost:1313/post/introduction/</link>
      <pubDate>Mon, 25 Jan 2021 15:43:24 +0800</pubDate>
      
      <guid>http://localhost:1313/post/introduction/</guid>
      <description>本篇主要介绍机器学习主要概念。 Learning Map **机器学习就是自动找函数。**例如，语音识别要找到从声音讯号到文字的函数，图像识别要找从图片到文字的函数</description>
    </item>
    
    <item>
      <title>Regression: Case Study</title>
      <link>http://localhost:1313/post/regression/</link>
      <pubDate>Mon, 25 Jan 2021 14:49:49 +0800</pubDate>
      
      <guid>http://localhost:1313/post/regression/</guid>
      <description>预测宝可梦进化后的CP (Combat Power)值：期望根据已有的宝可梦进化前后的信息，来预测某只宝可梦进化后的CP值的大小。 设定参数 输入$x$：一只宝</description>
    </item>
    
    <item>
      <title>Covolutional Neural Network</title>
      <link>http://localhost:1313/post/cnn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/cnn/</guid>
      <description>为什么在图像上使用CNN CNN v.s. DNN CNN一般用作影像处理，把图片转化成pixel，输出的是N个class。第1个layer是最底层的特征，越往后</description>
    </item>
    
  </channel>
</rss>
