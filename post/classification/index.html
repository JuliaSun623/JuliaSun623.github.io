<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Classification: Probabilistic Generative Model - Yu Sun</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Yu Sun" /><meta name="description" content="概念 任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。 依旧用宝可梦的例子：宝可" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.80.0 with theme even" />


<link rel="canonical" href="http://localhost:1313/post/classification/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.2e81bbed97b8b282c1aeb57488cc71c8d8c8ec559f3931531bd396bf31e0d4dd.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Classification: Probabilistic Generative Model" />
<meta property="og:description" content="概念 任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。 依旧用宝可梦的例子：宝可" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/classification/" />
<meta property="article:published_time" content="2021-01-27T10:32:36+08:00" />
<meta property="article:modified_time" content="2021-01-27T10:32:36+08:00" />
<meta itemprop="name" content="Classification: Probabilistic Generative Model">
<meta itemprop="description" content="概念 任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。 依旧用宝可梦的例子：宝可">
<meta itemprop="datePublished" content="2021-01-27T10:32:36+08:00" />
<meta itemprop="dateModified" content="2021-01-27T10:32:36+08:00" />
<meta itemprop="wordCount" content="5029">



<meta itemprop="keywords" content="机器学习,NLP,Classification," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Classification: Probabilistic Generative Model"/>
<meta name="twitter:description" content="概念 任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。 依旧用宝可梦的例子：宝可"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Yu Sun&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Yu Sun&#39;s Blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Classification: Probabilistic Generative Model</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-01-27 </span>
        <div class="post-category">
            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85/"> 机器学习李宏毅 </a>
            </div>
          <span class="more-meta"> 约 5029 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#概念">概念</a>
          <ul>
            <li><a href="#输入数值化">输入数值化</a></li>
          </ul>
        </li>
        <li><a href="#如何分类">如何分类</a>
          <ul>
            <li><a href="#可以将classification看作regression处理吗">可以将Classification看作Regression处理吗</a></li>
            <li><a href="#理想的classification方法">理想的Classification方法</a></li>
            <li><a href="#generative-model">Generative Model</a></li>
            <li><a href="#进行classification">进行Classification</a></li>
          </ul>
        </li>
        <li><a href="#修改model">修改Model</a></li>
        <li><a href="#classification三步走">Classification三步走</a>
          <ul>
            <li><a href="#1-确定modelfunction-set">1. 确定model（function set）</a></li>
            <li><a href="#2-定义如何判断为好的function">2. 定义如何判断为好的function</a></li>
            <li><a href="#3-选择最好的function">3. 选择最好的function</a></li>
          </ul>
        </li>
        <li><a href="#概率分布">概率分布</a>
          <ul>
            <li><a href="#朴素贝叶斯分类naive-bayes-classifier">朴素贝叶斯分类（Naive Bayes Classifier）</a></li>
            <li><a href="#posterior-probability后验概率">Posterior Probability（后验概率）</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="概念">概念</h2>
<p>任务：找一个function，它的input是一个object，它的输出是这个object属于哪一个class。</p>
<p>依旧用宝可梦的例子：宝可梦有18种属性，分类问题就是输入一个宝可梦，输出这个宝可梦属于哪种属性。</p>
<h3 id="输入数值化">输入数值化</h3>
<p>要对宝可梦分类，首先需要将其数值化以作为function的input，即用一组数字来描述一只宝可梦的特性。</p>
<h2 id="如何分类">如何分类</h2>
<h3 id="可以将classification看作regression处理吗">可以将Classification看作Regression处理吗</h3>
<h4 id="思路">思路</h4>
<p>给定训练集$(x^1,\hat y^1)$，以binary classification为例，在训练时让输入为class 1的输出为1，输入为class 2的输出为-1；那么在测试时，regression的output是一个数值，它接近1则说明它是class 1，它接近-1则说明它是class 2。</p>
<h4 id="可能遇到的问题">可能遇到的问题</h4>
<p>假设现在我们的model是$y=b+w_1x_1+x_2x_2$，input是两个feature $x_1,x_2$。输出有两个class，蓝色的是class 1，红色的是class 2。如果用Regression的做法，那么就希望蓝色的这些属于class 1的宝可梦，input到Regression的model，output越接近1越好；红色的属于class 2的宝可梦，input到Regression的model，output越接近-1越好。</p>
<p>如下左图，表现较好，但是只会出现在样本点比较集中地分布在output为-1和1的情况。如果像下图右侧所示，我们已经知道绿线为最好的那个model的分界线，它的左上角的值小于0，右下角的值大于0，越往右下方值越大。所以右下角这些点用绿线对应的model做Regression时，output是远大于1的。但是做Regression的时候，实际上已经给所有的点打上了-1或1的标签，因此蓝色点在model中的output都应越接近1越好。所以这些output远大于1的点，它对于绿线对应的model来说是error，是不好的。因此这组样本点通过Regression训练出来的model，会是紫色这条分界线对应的model，因为相对于绿线，它“减小”了由右下角这些点所带来的error。</p>
<img src='https://s3.ax1x.com/2021/01/28/ySnsCq.jpg' style="zoom:40%;">
<p>Regression的output是连续性质的数值，而classification要求的output是离散性质的点，因此很难找到一个Regression的function使大部分样本点的output都集中在某几个离散的点附近。因此，<strong>Regression定义model好坏的定义方式对classification来说是不适用的</strong>。</p>
<p>⚠️ 如果是多元分类问题，把class 1的target当做是1，class 2的target当做是2，class 3的target当做是3的做法是错误的。因为这样Regression会认为class 1和class 2的关系是比较接近的，class 2和class 3的关系是比较接近的，而class 1和class 3的关系是比较疏远的；但是当这些class之间并没有什么特殊的关系的时候，这样的标签用Regression是没有办法得到好的结果的。</p>
<h3 id="理想的classification方法">理想的Classification方法</h3>
<img src='https://s3.ax1x.com/2021/01/28/ySnoP1.jpg' style="zoom:40%;">
<h4 id="model">Model</h4>
<p>我们要找的function f(x)里面会有另外一个function g(x)，当input x输入后，如果g(x)&gt;0，那f(x)的输出就是class 1；如果g(x)&lt;0，那f(x)的输出就是class 2。这个方法保证了function的output都是离散的表示class的数值。</p>
<h4 id="loss-function">Loss function</h4>
<p>如果选了某个function f，则loss是在训练集上预测错误的次数。但是这个loss function没有办法微分，是无法用gradient descent的方法去解的。有Perceptron、SVM这些方法可以用，但这里先用另外一个solution来解决这个问题</p>
<h3 id="generative-model">Generative Model</h3>
<h4 id="概率论知识">概率论知识</h4>
<p>假设我们考虑一个二元分类的问题，我们拿到一个input $x$，想要知道这个$x$属于class 1或class 2的概率。这实际上就是一个<strong>贝叶斯公式</strong>，$x$属于class 1的概率就等于class 1自身发生的概率✖️从class 1里取出$x$这种颜色的球的概率➗class 1和 class 2里取出x这种颜色的球的概率（分母后者是全概率公式）：</p>
<img src='https://s3.ax1x.com/2021/01/28/ySupGt.jpg' style="zoom:40%;">
<p>因此需要从训练集中把红框的四个值算出来。Generative Model可以计算某个$x$出现的几率，可以用这个分布产生$x$。</p>
<h5 id="prior">Prior</h5>
<p>计算prior：$P(C_1),P(C_2)$。</p>
<p>假设我们还是考虑二元分类问题，在Training data里面分一部分validation出来模拟testing的情况。假设在Training data里面，有79只水系宝可梦，61只一般系宝可梦，那么$P(C_1)=\frac{79}{79+61},P(C_2)=\frac{61}{79+61}$。</p>
<h5 id="probability-from-class">Probability from Class</h5>
<p>计算$P(x|C_1),P(x|C_2)$。</p>
<p>每一只宝可梦都是用一组特征值组成的向量来表示的，在这个vector里一共有七种不同的feature，为了方便可视化，这里先只考虑Defense和SP Defence这两种feature。</p>
<p>假设海龟的vector是[103, 45]，虽然这个点在已有的数据里并没有出现过，但是不可以认为它出现的概率为0，我们需要用已有的数据去估测海龟出现的可能性。假定水系神奇宝贝的Defense和SP Defense是从一个Gaussian的distribution里面sample出来的，下图只是采样了79个点之后得到的分布，但是从高斯分布里采样出海龟这个点的几率并不是0。</p>
<img src='https://s3.ax1x.com/2021/01/28/ySuqWq.jpg' style="zoom:40%;">
<h4 id="gaussian-distribution">Gaussian Distribution</h4>
<p>输入是宝可梦$x$，输出是从分布中sample $x$的概率。分布的形状由均值$\mu$和协方差矩阵$\Sigma$组成，然后可以得到分布:
$$
f_{\mu,\Sigma}=\frac{1}{(2\pi)^{D/2}}\frac1{|\Sigma|^{1/2}}exp{-\frac12(x-\mu)^T\Sigma^{-1}(x-\mu)}
$$
接下来的问题就是怎么去找出这个Gaussian，**只需要去估测出这个Gaussian的均值$\mu$和协方差$\Sigma $即可**。</p>
<h4 id="maximum-likelihood">Maximum Likelihood</h4>
<p>估测的方法就是<strong>极大似然估计法(Maximum Likelihood)</strong>。任何一个高斯分布都能sample出这79个点，只是sample概率高低的问题。给出了高斯分布的$\mu$和$\Sigma$，可以算出高斯分布sample出79个$x$的概率，可能性记为$L(\mu,\Sigma)=f_{\mu,\Sigma}(x^1),&hellip;,f_{\mu,\Sigma}(x^{79})$。现在要找到一个高斯分布$(\mu^*,\Sigma^*)$使得$L(\mu,\Sigma)$最大。即**得到的分布情况与当前已知79点的分布情况相同**。</p>
<img src='https://s3.ax1x.com/2021/01/28/ySGKDx.jpg' style="zoom:30%;">
<h3 id="进行classification">进行Classification</h3>
<p>现在我们已知下面的数据和分布：</p>
<img src='https://s3.ax1x.com/2021/01/28/ySGUKI.jpg' style="zoom:40%;">
<p>只要带入某一个input x，就可以通过这个式子计算出它是否是class 1了。</p>
<h2 id="修改model">修改Model</h2>
<p>其实之前使用的model是不常见的，你是不会经常看到给每一个Gaussian都有自己的mean和covariance，比较常见的做法是，<strong>不同的class可以share同一个cocovariance matrix</strong>。</p>
<p>其实variance是跟input的feature size的平方成正比的，所以当feature的数量很大的时候，大小的增长是可以非常快的。在这种情况下，给不同的Gaussian以不同的covariance matrix，会造成model的参数太多，而参数多会导致该model的variance过大，出现overfitting的现象，因此对不同的class使用同一个covariance matrix，可以有效减少参数。</p>
<p>此时就把$\mu_1,\mu_2$和共同的$\Sigma$一起去合成一个极大似然函数，此时可以发现，得到的$\mu_1,\mu_2$和原来一样，还是各自的均值，而$\Sigma$则是原先$\Sigma_1,\Sigma_2$的加权。</p>
<img src='https://s3.ax1x.com/2021/01/28/ySJtFU.jpg' style="zoom:40%;">
<p>结果发现，class 1和class 2在没有共用covariance matrix之前，它们的分界线是一条曲线；如果共用covariance matrix的话，它们之间的分界线就会变成一条直线。这样的model，我们也称之为linear model（尽管Gaussian不是linear的，但是它分两个class的boundary是linear）。</p>
<h2 id="classification三步走">Classification三步走</h2>
<p>现在让我们来回顾一下做classification的三个步骤，实际上也就是做machine learning的三个步骤：</p>
<h3 id="1-确定modelfunction-set">1. 确定model（function set）</h3>
<p>$$
P(C_1|x)=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}
$$</p>
<p>这些required probability $P(C)$ 和probability distribution $P(x|C)$ 就是model的参数，选择不同的Probability distribution（比如不同的分布函数，或者是不同参数的Gaussian distribution），就会得到不同的function。把这些不同参数的Gaussian distribution集合起来，就是一个model。如果不适用高斯函数而选择其他分布函数，就是一个新的model了</p>
<p>当这个posterior Probability $P(C|x)&gt;0.5$的话，就output class 1，反之就output class 2。</p>
<h3 id="2-定义如何判断为好的function">2. 定义如何判断为好的function</h3>
<p>对于Gaussian distribution这个model来说，我们要评价的是决定这个高斯函数形状的均值$\mu$和协方差$\Sigma$这两个参数的好坏，而极大似然函数的输出值$L(\mu,\Sigma)$，就评价了这组参数的好坏</p>
<h3 id="3-选择最好的function">3. 选择最好的function</h3>
<p>找到的那个最好的function，就是使$L(\mu,\Sigma)$值最大的那组参数</p>
<h2 id="概率分布">概率分布</h2>
<p>通过人的智慧选择Probability distribution概率分布函数。如果你选择的是简单的分布函数(参数比较少)，那你的bias就大，variance就小；如果你选择复杂的分布函数，那你的bias就小，variance就大。那你就可以用data set来判断一下，用什么样的Probability distribution作为model是比较好的。</p>
<h3 id="朴素贝叶斯分类naive-bayes-classifier">朴素贝叶斯分类（Naive Bayes Classifier）</h3>
<p>假设$x=[x_1,&hellip;,x_k]$中每一个dimension $x_k$的分布都是相互独立的，它们之间的covariance都是0，那我们就可以把$x$产生的几率拆解成$x_1,&hellip;,x_k$产生的几率之积。</p>
<p>这里每一个dimension的分布函数都是一维的Gaussian distribution，如果这样假设的话，原来多维度的Gaussian，它的covariance matrix变成是diagonal（对角的），在不是对角线的地方，值都是0，这样就可以更加减少需要的参数量，就可以得到一个更简单的model</p>
<p>这种方法就是朴素贝叶斯分类。如果明确了所有的feature之间是相互独立不相关的，使用朴素贝叶斯分类法的performance是会很好的。如果这个假设是不成立的，那么Naive bayes classfier的bias就会很大，它就不是一个好的classifier（朴素贝叶斯分类法本质就是减少参数）。</p>
<p>总之，寻找model总的原则是，<strong>尽量减少不必要的参数，但是必然的参数绝对不能少</strong></p>
<h3 id="posterior-probability后验概率">Posterior Probability（后验概率）</h3>
<p>下图介绍了sigmoid function：</p>
<img src='https://s3.ax1x.com/2021/01/28/ySwIgO.jpg' style="zoom:40%;">
<p>当$\Sigma_1,\Sigma_2$共用一个时，经过化简相消z就变成了一个linear的function，$x$的系数是一个vector $w$，后面的一大串数字其实就是一个常数项$b$。</p>
<img src='https://s3.ax1x.com/2021/01/28/yS0YRK.jpg' style="zoom:40%;">
<p>$P(C_1|x)=\sigma(w·x+b)$这个式子就解释了，<strong>当class 1和class 2共用$\Sigma$的时候，它们之间的boundary会是linear的</strong>。</p>
<p>那在Generative model里面，我们做的事情是，我们用某些方法去找出$N_1,N_2,\mu_1,\mu_2,\Sigma$，找出这些以后就算出$w$和$b$，把它们代进这个式子，就可以算概率。但是，当你看到这个式子的时候，你可能会有一个直觉的想法，我们的最终目标都是要找一个vector $w$和const $b$，我们何必先去搞个概率，算出一些什么的，然后再回过头来又去算$w$和$b$，这不是舍近求远吗？</p>
<p>所以下节课讲解直接找出$w$和$b$的方法。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Yu Sun</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2021-01-27
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
          <a href="/tags/nlp/">NLP</a>
          <a href="/tags/classification/">Classification</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/logistic_regression/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Logistic Regression</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/optimization/">
            <span class="next-text nav-default">New Optimizers for Deep Learning</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:cnsdytsy@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://stackoverflow.com/users/15074966/ysun" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://github.com/JuliaSun623" class="iconfont icon-github" title="github"></a>
      <a href="https://www.instagram.com/chubbyfishfish/" class="iconfont icon-instagram" title="instagram"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>olOwOlo</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
